{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score, adjusted_mutual_info_score, confusion_matrix\n",
    "import umap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Definir la clase KMeans personalizada\n",
    "class Kmeans:\n",
    "    def __init__(self, k=20, n_iter=500):\n",
    "        self.k = k\n",
    "        self.n_iter = n_iter\n",
    "        self.labels = None\n",
    "        self.centroids = None\n",
    "\n",
    "    def fit(self , X):\n",
    "        centroids = self.init_centroids(X)\n",
    "        \n",
    "        i = 0\n",
    "        while(i < self.n_iter):\n",
    "            labels = self.set_labels(X, centroids)\n",
    "            new_centroids = self.update_centroids(X, labels)\n",
    "\n",
    "            centroids = new_centroids\n",
    "            i += 1\n",
    "        self.centroids = centroids\n",
    "        self.labels = labels\n",
    "\n",
    "    def init_centroids(self , X):\n",
    "        index_rand = np.random.choice(X.shape[0], self.k, replace=False)\n",
    "        return X[index_rand]\n",
    "    \n",
    "    def set_labels(self , X, centroids):\n",
    "        distances = np.sum((X[:, np.newaxis] - centroids)**2, axis=2)\n",
    "        labels = np.argmin(distances, axis=1)\n",
    "        return labels\n",
    "    \n",
    "    def update_centroids(self , X, labels):\n",
    "        centroids = np.zeros((self.k, X.shape[1]))\n",
    "        for i in range(self.k):\n",
    "            cluster_points = X[labels == i]\n",
    "            if len(cluster_points) > 0:\n",
    "                centroids[i] = np.mean(cluster_points, axis=0)\n",
    "        return centroids\n",
    "\n",
    "# Cargar los datos de features\n",
    "train_features_df = pd.read_csv('video_features_id.csv', header=None)\n",
    "val_features_df = pd.read_csv('validation_features_id.csv', header=None)\n",
    "test_features_df = pd.read_csv('test_features_id.csv', header=None)\n",
    "\n",
    "# Cargar los datos originales para obtener las etiquetas\n",
    "train_labels_df = pd.read_csv('train.csv')\n",
    "val_labels_df = pd.read_csv('val.csv')\n",
    "submission_template = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "# Asegurarnos de que las filas coincidan por ID\n",
    "train_df = train_features_df.set_index(0).join(train_labels_df.set_index('youtube_id'), how='inner')\n",
    "val_df = val_features_df.set_index(0).join(val_labels_df.set_index('youtube_id'), how='inner')\n",
    "test_df = test_features_df.set_index(0)  # Solo características, sin etiquetas\n",
    "\n",
    "# Separar los labels y los features en los datos de entrenamiento\n",
    "train_labels = train_df['label']\n",
    "train_features = train_df.drop(columns=['label'])\n",
    "\n",
    "# Normalización de los datos\n",
    "scaler = StandardScaler()\n",
    "train_features_scaled = scaler.fit_transform(train_features.dropna())\n",
    "\n",
    "# Reducir la dimensionalidad usando UMAP\n",
    "umap_reducer = umap.UMAP(n_components=50, random_state=42)\n",
    "train_reduced_features = umap_reducer.fit_transform(train_features_scaled)\n",
    "\n",
    "# Ejecutar KMeans personalizado\n",
    "kmeans = Kmeans(k=train_labels.nunique())\n",
    "kmeans.fit(train_reduced_features)\n",
    "\n",
    "# Calcular y reportar métricas de clasificación\n",
    "silhouette = silhouette_score(train_reduced_features, kmeans.labels)\n",
    "print(f'Silhouette Score: {silhouette:.2f}')\n",
    "\n",
    "# Graficar las métricas de clasificación\n",
    "metrics = {'Silhouette Score': silhouette}\n",
    "metric_names = list(metrics.keys())\n",
    "metric_values = list(metrics.values())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(metric_names, metric_values, color=['blue', 'green', 'red'])\n",
    "plt.xlabel('Métricas de Clasificación')\n",
    "plt.ylabel('Valor')\n",
    "plt.title('Métricas de Clasificación para KMeans con UMAP')\n",
    "plt.ylim(0, 1)\n",
    "plt.savefig('kmeans_metrics.png')\n",
    "plt.show()\n",
    "\n",
    "# Análisis y discusión de los resultados\n",
    "print(\"\\nAnálisis y Discusión de los Resultados:\")\n",
    "print(\"Silhouette Score mide qué tan similares son los puntos dentro del mismo clúster comparados con los puntos en diferentes clústeres.\")\n",
    "\n",
    "# Asignar clusters al conjunto de validación\n",
    "val_features = val_df.drop(columns=['label'])\n",
    "val_features_clean = val_features.dropna()\n",
    "val_features_scaled = scaler.transform(val_features_clean)\n",
    "val_reduced_features = umap_reducer.transform(val_features_scaled)\n",
    "val_clusters = kmeans.set_labels(val_reduced_features, kmeans.centroids)\n",
    "\n",
    "# Añadir los clusters predichos al DataFrame de validación\n",
    "val_df_clean = val_df.loc[val_features_clean.index].copy()\n",
    "val_df_clean['Predicted_Cluster'] = val_clusters\n",
    "\n",
    "# Mapeo automático de clusters a etiquetas\n",
    "cluster_to_label = {}\n",
    "for cluster in set(val_clusters):\n",
    "    cluster_labels = val_df_clean[val_df_clean['Predicted_Cluster'] == cluster]['label']\n",
    "    most_common_label = cluster_labels.mode().iloc[0]  # Obtener la etiqueta más común en cada cluster\n",
    "    cluster_to_label[cluster] = most_common_label\n",
    "\n",
    "print(\"Mapeo de clusters a etiquetas:\", cluster_to_label)\n",
    "\n",
    "# Aplicar el mapeo\n",
    "val_df_clean['Predicted_Label'] = val_df_clean['Predicted_Cluster'].map(cluster_to_label)\n",
    "\n",
    "# Calcular la precisión de la validación\n",
    "val_accuracy = sum(val_df_clean['label'] == val_df_clean['Predicted_Label']) / len(val_df_clean)\n",
    "print(f'Precisión de la validación: {val_accuracy:.2f}')\n",
    "\n",
    "# Crear y mostrar la matriz de confusión\n",
    "conf_matrix = confusion_matrix(val_df_clean['label'], val_df_clean['Predicted_Label'])\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Matriz de Confusión para la Validación')\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.show()\n",
    "\n",
    "# Graficar los clusters\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.scatterplot(x=train_reduced_features[:, 0], y=train_reduced_features[:, 1], hue=kmeans.labels, palette='viridis')\n",
    "plt.title('Clusters de KMeans en el conjunto de entrenamiento')\n",
    "plt.xlabel('Componente UMAP 1')\n",
    "plt.ylabel('Componente UMAP 2')\n",
    "plt.legend(title='Cluster')\n",
    "plt.savefig('kmeans_clusters.png')\n",
    "plt.show()\n",
    "\n",
    "# Preprocesar el conjunto de prueba de manera similar\n",
    "test_features_clean = test_df.dropna()\n",
    "test_features_scaled = scaler.transform(test_features_clean)\n",
    "test_reduced_features = umap_reducer.transform(test_features_scaled)\n",
    "\n",
    "# Predecir con KMeans personalizado\n",
    "test_clusters = kmeans.set_labels(test_reduced_features, kmeans.centroids)\n",
    "\n",
    "# Añadir los clusters predichos al DataFrame de prueba\n",
    "test_df_clean = test_df.loc[test_features_clean.index].copy()\n",
    "test_df_clean['Predicted_Cluster'] = test_clusters\n",
    "\n",
    "# Aplicar el mapeo\n",
    "test_df_clean['Predicted_Label'] = test_df_clean['Predicted_Cluster'].map(cluster_to_label)\n",
    "\n",
    "# Guardar las predicciones del conjunto de prueba en el archivo CSV según la plantilla\n",
    "submission = pd.DataFrame({\n",
    "    'youtube_id': test_df_clean.index,\n",
    "    'label': test_df_clean['Predicted_Label']\n",
    "})\n",
    "submission.to_csv('test_predictions.csv', index=False)\n",
    "\n",
    "print(\"Predicciones del conjunto de prueba guardadas en 'test_predictions.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
